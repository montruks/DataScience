{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6652db97",
   "metadata": {},
   "outputs": [],
   "source": [
    "c\n",
    "import string\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66553822",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"IMDb.csv\", \"r\", encoding = \"UTF-8\") as f:\n",
    "    IMDb = list(csv.reader(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6a0f3fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMDb = IMDb[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e721c5e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(docs):\n",
    "    \"\"\"\n",
    "    Input: a list of strings. Each item is a document to tokenize.\n",
    "    Output: a list of lists. Each item is a list containing the tokens of the relative document.\n",
    "    \"\"\"\n",
    "    tokens = []\n",
    "    for doc in docs:\n",
    "        for punct in string.punctuation:\n",
    "            doc = doc.replace(punct, \" \")\n",
    "        tokens.append([token.lower() for token in doc.split(\" \") if token])\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b1d2eb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [line[0] for line in IMDb]\n",
    "tokens = tokenize(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41c55a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_TF(tokens):\n",
    "    \"\"\"\n",
    "    Input: a list of lists. Each item is a list containing the tokens of the relative document.\n",
    "    Output: a list of dictionaries. Each item is a dictionary containing the frequency of the token in the document.\n",
    "    \"\"\"\n",
    "    TF = []\n",
    "    for doc_tokens in tokens:\n",
    "        TF.append({token: doc_tokens.count(token) for token in set(doc_tokens)})\n",
    "    return TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5f5e3b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF = compute_TF(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "608b7a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_DF(tokens):\n",
    "    \"\"\"\n",
    "    Input: a list of lists. Each item is a list containing the tokens of the relative document.\n",
    "    Output: a dictionary. Each item contain the document frequency.\n",
    "    \"\"\"\n",
    "    DF = {}\n",
    "    for doc_tokens in tokens:\n",
    "        for token in set(doc_tokens):\n",
    "            DF[token] = DF.get(token, 0) + 1\n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "363c58e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DF = compute_DF(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f34ca63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_IDF(DF, N):\n",
    "    \"\"\"\n",
    "    Input: a dictionary. Each item contain the document frequency.\n",
    "    Input: the total number of documents\n",
    "    Output: a dictionary. Each item contain the inverse document frequency.\n",
    "    \"\"\"\n",
    "    IDF = {}\n",
    "    for token in DF:\n",
    "        IDF[token] = math.log(N / DF.get(token))\n",
    "    return IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e92dffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = len(IMDb)\n",
    "IDF = compute_IDF(DF, N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "10db63d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "words = list(IDF)\n",
    "words.sort(key = lambda word: IDF.get(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f78a476",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'a', 'and', 'of', 'to', 'this', 'is', 'it', 'in', 'that']\n",
      "['prousalis', 'rou√©', 'infantalising', 'orientalist', 'jayden', 'imy', 'camora', 'capiche', 'jowls', 'repleat']\n"
     ]
    }
   ],
   "source": [
    "print(words[0:10])\n",
    "print(words[-10:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89929c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_TF_IDF(TF, IDF):\n",
    "    \"\"\"\n",
    "    Input: a list of dictionaries. Each item is a dictionary containing the frequency of the token in the document.\n",
    "    Input: a dictionary. Each item contain the inverse document frequency.\n",
    "    Output: a list of dictionaries. Each item is a dictionary containing the TF-IDF of the token in the document.\n",
    "    \"\"\"\n",
    "    TF_IDF = []\n",
    "    for doc_TF in TF:\n",
    "        TF_IDF.append({token: doc_TF.get(token) * IDF.get(token) for token in doc_TF})\n",
    "    return TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5ac91056",
   "metadata": {},
   "outputs": [],
   "source": [
    "TF_IDF = compute_TF_IDF(TF, IDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86d79024",
   "metadata": {},
   "outputs": [],
   "source": [
    "def norm(d):\n",
    "    \"\"\"Compute the L2-norm of a vector representation.\"\"\"\n",
    "    return sum([d.get(k) ** 2 for k in d]) ** 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1afb6ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dot_product(d1, d2):\n",
    "\"\"\"Compute the dot product between two vector representations.\"\"\"\n",
    "word_set = set(list(d1.keys()) + list(d2.keys()))\n",
    "return sum([( d1.get(d, 0.0) * d2.get(d, 0.0)) for d in word_set ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b815945",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(d1, d2):\n",
    "\"\"\"\n",
    "Compute the cosine similarity between documents d1 and d2.\n",
    "Input: two dictionaries representing the TF-IDF vectors for documents\n",
    "d1 and d2.\n",
    "Output: the cosine similarity.\n",
    "\"\"\"\n",
    "return dot_product(d1, d2) / (norm(d1) * norm(d2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
